{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 模型训练与评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# 性能评价函数\n",
    "# 每个优惠券核销预测的平均AUC作为评价标准\n",
    "# 对每个优惠券coupon_id单独计算核销预测的AUC值\n",
    "# 再对所有优惠券AUC值求平均作为最终的评价函数\n",
    "# coupon平均AUC计算\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import numpy as np\n",
    "def myauc(test):\n",
    "    testgroup = test.groupby(['coupon_id'])\n",
    "    aucs = []\n",
    "    for i in testgroup:\n",
    "        coupon_df = i[1]\n",
    "        # 测算AUC必须大于1个类别\n",
    "        if len(coupon_df['label'].unique()) < 2:\n",
    "            continue\n",
    "        auc = roc_auc_score(coupon_df['label'], coupon_df['pred'])\n",
    "        aucs.append(auc)\n",
    "    return np.average(aucs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "######### 全局参数 ############\n",
    "id_col_names = ['user_id', 'coupon_id', 'date_received']\n",
    "target_col_name = 'label'\n",
    "id_target_cols = ['user_id', 'coupon_id', 'date_received', 'label']\n",
    "myeval = 'roc_auc'\n",
    "cvscore = 0\n",
    "\n",
    "######### 目录定义 ############\n",
    "datapath = './dataset/'\n",
    "featurepath = './feature/'\n",
    "resultpath = './result/'\n",
    "tmppath = './tmp/'\n",
    "scorepath = './score/'\n",
    "\n",
    "######### 工具函数 ############\n",
    "# 返回ID列\n",
    "def get_id_df(df):\n",
    "    return df[id_col_names]\n",
    "\n",
    "# 返回target列\n",
    "def get_target_df(df):\n",
    "    return df[target_col_name]\n",
    "\n",
    "# 返回特征列\n",
    "def get_predictors_df(df):\n",
    "    predictors = [f for f in df.columns if f not in id_target_cols]\n",
    "    return df[predictors]\n",
    "\n",
    "# 按特征名读取训练集\n",
    "def read_featurefile_train(featurename):\n",
    "    df = pd.read_csv(featurepath + 'train_' + featurename + '.csv', sep=',', encoding='utf-8')\n",
    "    df.fillna(0, inplace=True)\n",
    "    return df\n",
    "\n",
    "# 按特征名读取测试集\n",
    "def read_featurefile_test(featurename):\n",
    "    df = pd.read_csv(featurepath + 'test_' + featurename + '.csv', sep=',', encoding='utf-8')\n",
    "    df.fillna(0, inplace=True)\n",
    "    return df\n",
    "\n",
    "# 按特征名读取数据\n",
    "def read_data(featurename):\n",
    "    traindf = read_featurefile_train(featurename)\n",
    "    testdf = read_featurefile_test(featurename)\n",
    "    return traindf, testdf\n",
    "\n",
    "# 调用分类算法\n",
    "def get_sklearn_model(model_name):\n",
    "\n",
    "    if model_name == 'NB':\n",
    "        return MultinomialNB(alpha=0.01)\n",
    "\n",
    "    elif model_name == 'LR':\n",
    "        return LogisticRegression(penalty='l2')\n",
    "\n",
    "    elif model_name == 'KNN':\n",
    "        return KNeighborsClassifier()\n",
    "\n",
    "    elif model_name == 'RF':\n",
    "        return RandomForestClassifier()\n",
    "\n",
    "    elif model_name == 'DT':\n",
    "        return DecisionTreeClassifier()\n",
    "\n",
    "    elif model_name == 'SVC':\n",
    "        return SVC(kernel='rbf')\n",
    "\n",
    "    elif model_name == 'GBDT':\n",
    "        return GradientBoostingClassifier()\n",
    "\n",
    "    elif model_name == 'XGB':\n",
    "        return XGBClassifier()\n",
    "\n",
    "    elif model_name == 'LGB':\n",
    "        return LGBMClassifier()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import learning_curve\n",
    "# 画学习曲线\n",
    "def plot_learning_curve(estimator,\n",
    "                        title,\n",
    "                        X,\n",
    "                        y,\n",
    "                        ylim=None,\n",
    "                        cv=None,\n",
    "                        n_jobs=1,\n",
    "                        train_sizes=[0.01, 0.02, 0.05, 0.1, 0.2, 0.3]):\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    plt.xlabel('training examples')\n",
    "    plt.ylabel('score')\n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        estimator,\n",
    "        X,\n",
    "        y,\n",
    "        cv=cv,\n",
    "        scoring=myeval,\n",
    "        n_jobs=n_jobs,\n",
    "        train_sizes=train_sizes\n",
    "    )\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "\n",
    "    plt.grid()\n",
    "    plt.fill_between(train_sizes,\n",
    "                     train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std,\n",
    "                     alpha=0.1,\n",
    "                     color='r')\n",
    "    plt.fill_between(train_sizes,\n",
    "                     test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std,\n",
    "                     alpha=0.1,\n",
    "                     color='g')\n",
    "    plt.plot(train_sizes,\n",
    "             train_scores_mean,\n",
    "             'o-',\n",
    "             color='r',\n",
    "             label='training score')\n",
    "    plt.plot(train_sizes,\n",
    "             test_scores_mean,\n",
    "             'o-',\n",
    "             color='g',\n",
    "             label='cross-validation score')\n",
    "    plt.legend(loc='best')\n",
    "    return plt\n",
    "\n",
    "# 画算法的学习曲线，为加快画图速度，最多选20%的数据\n",
    "def plot_curve_single(traindf,\n",
    "                      classifier,\n",
    "                      cvnum,\n",
    "                      train_sizes=[0.01, 0.02, 0.05, 0.1, 0.2, 0.3]):\n",
    "    X = get_predictors_df(traindf)\n",
    "    y = get_target_df(traindf)\n",
    "    estimator = get_sklearn_model(classifier)\n",
    "    title = 'learning curve of' + classifier + ', cv:' + str(cvnum)\n",
    "    plot_learning_curve(estimator,\n",
    "                        title,\n",
    "                        X,\n",
    "                        y,\n",
    "                        ylim=(0, 1.01),\n",
    "                        cv=cvnum,\n",
    "                        train_sizes=train_sizes)\n",
    "\n",
    "# 按照日期分割\n",
    "def test_model(traindf, classifier):\n",
    "    train = traindf[traindf.date_received < 20160515].copy()\n",
    "    test = traindf[traindf.date_received >= 20160515].copy()\n",
    "    train_data = get_predictors_df(train).copy()\n",
    "    train_target = get_target_df(train).copy()\n",
    "    test_data = get_predictors_df(test).copy()\n",
    "    test_target = get_target_df(test).copy()\n",
    "    clf = get_sklearn_model(classifier)\n",
    "    clf.fit(train_data, train_target)\n",
    "    result = clf.predict_proba(test_data)[:,1]\n",
    "    test['pred'] = result\n",
    "    score = roc_auc_score(test_target, result)\n",
    "    print(classifier + '总体AUC：', score)\n",
    "    score_coupon = myauc(test)\n",
    "    print(classifier + 'Coupon AUC: ', score_coupon)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "def test_model_split(traindf, classifier):\n",
    "    target = get_target_df(traindf).copy()\n",
    "    train_all, test_all,train_target,test_target = train_test_split(\n",
    "        traindf, target, test_size=0.2, random_state=0\n",
    "    )\n",
    "\n",
    "    train_data = get_predictors_df(train_all).copy()\n",
    "    test_data = get_predictors_df(test_all).copy()\n",
    "    clf = get_sklearn_model(classifier)\n",
    "    clf.fit(train_data, train_target)\n",
    "    result = clf.predict_proba(test_data)[:,1]\n",
    "    test = test_all.copy()\n",
    "    test['pred'] = result\n",
    "    score = roc_auc_score(test_target, result)\n",
    "    print(classifier + '总体AUC：', score)\n",
    "    score_coupon = myauc(test)\n",
    "    print(classifier + 'Coupon AUC: ', score_coupon)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 不同算法模型的性能对比"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# 1. 朴素贝叶斯"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# 2. 逻辑回归"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# 3. 决策树"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# 4. 随机森林"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# 5. XGBoost"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# 6. LightGBM"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 结果输出"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 预测函数\n",
    "def classifier_df_simple(train_feat, test_feat, classifier):\n",
    "    model = get_sklearn_model(classifier)\n",
    "    model.fit(get_predictors_df(train_feat), get_target_df(train_feat))\n",
    "    predicted = pd.DataFrame(\n",
    "        model.predict_proba(get_predictors_df(test_feat))[:, 1]\n",
    "    )\n",
    "    return predicted\n",
    "\n",
    "# 输出结果函数\n",
    "def output_predicted(predicted, resultfile, test_feat):\n",
    "    predicted = round(predicted, 3)\n",
    "    resultdf = get_id_df(test_feat).copy()\n",
    "    resultdf['Probability'] = predicted\n",
    "    return resultdf\n",
    "\n",
    "predicted = classifier_df_simple(train_f3, test_f3, 'LGB')\n",
    "\n",
    "# 生成结果数据\n",
    "result = output_predicted(predicted, 'sf3_LGB.csv', test_f3)\n",
    "# 输出结果\n",
    "result.to_csv('sf3_lgb.csv', header=False, index=False, sep=',')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 模型验证"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 交叉验证"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_f3' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-9-1a67dc7a140b>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0msklearn\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmodel_selection\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mtrain_test_split\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 5\u001B[0;31m \u001B[0mtarget\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mget_target_df\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtrain_f3\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcopy\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      6\u001B[0m \u001B[0mtraindf\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtrain_f3\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcopy\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      7\u001B[0m train_all, test_all,train_target,test_target = train_test_split(\n",
      "\u001B[0;31mNameError\u001B[0m: name 'train_f3' is not defined"
     ]
    }
   ],
   "source": [
    "# 简单交叉验证\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "target = get_target_df(train_f3).copy()\n",
    "traindf = train_f3.copy()\n",
    "train_all, test_all,train_target,test_target = train_test_split(\n",
    "        traindf, target, test_size=0.2, random_state=0\n",
    "    )\n",
    "train_data = get_predictors_df(train_all).copy()\n",
    "test_data = get_predictors_df(test_all).copy()\n",
    "clf = LogisticRegression()\n",
    "clf.fit(train_data, train_target)\n",
    "train_pred = clf.predict_proba(train_data)[:,1]\n",
    "test_pred = clf.predict_proba(test_data)[:,1]\n",
    "\n",
    "score_train = roc_auc_score(train_target, train_pred)\n",
    "score_test = roc_auc_score(test_target, test_pred)\n",
    "\n",
    "print('logistic regression train' + '总体AUC：', score_train)\n",
    "print('logistic regression test' + '总体AUC：', score_test)\n",
    "\n",
    "train_all['pred'] = train_pred\n",
    "test_all['pred'] = test_pred\n",
    "\n",
    "print('logistic regression test' + 'coupon AUC：', myauc(train_all))\n",
    "print('logistic regression test' + 'coupon AUC：', myauc(test_all))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# K折交叉验证\n",
    "train = train_f3.copy()\n",
    "target = get_target_df(train_f3).copy()\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=5)\n",
    "\n",
    "for k, (train_index, test_index) in enumerate(kf.split(train)):\n",
    "    X_train, X_test, y_train, y_test = train[train_index], train[test_index], target[train_index], target[test_index]\n",
    "    clf = LogisticRegression()\n",
    "    clf = clf.fit(get_predictors_df(X_train), y_train)\n",
    "\n",
    "    train_pred = clf.predict_proba(get_predictors_df(X_train))[:,1]\n",
    "    test_pred = clf.predict_proba(get_predictors_df(X_test))[:,1]\n",
    "    score_train = roc_auc_score(y_train, train_pred)\n",
    "    score_test = roc_auc_score(y_test, test_pred)\n",
    "    X_train['pred'] = train_pred\n",
    "    X_test['pred'] = test_pred\n",
    "    print(k+1, '折' + 'logistic regression train' + '总体AUC：', score_train)\n",
    "    print(k+1, '折' + 'logistic regression test' + '总体AUC：', score_test)\n",
    "    print(k+1, '折' + 'logistic regression train' + 'coupon AUC：', myauc(X_train))\n",
    "    print(k+1, '折' + 'logistic regression test' + 'coupon AUC：', myauc(X_test))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# 留一法交叉验证和留P法交叉验证"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# StratifiedKFold 和 StratifiedShuffleSplit"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 模型比较"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 验证结果可视化"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 模型调参"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# 网格搜索"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# 随机搜索"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "# 启发式搜索"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 实际方案"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 1. 确定最佳学习率和迭代次数\n",
    "# 2. 确定max_depth和num_leaves\n",
    "# 3. 确定min_data_in_leaf和max_bin\n",
    "# 4. 确定feature_fraction，bagging_fraction，bagging_freq\n",
    "# 5. 确定lambda_l1和lambda_l2\n",
    "# 6. 确定min_split_gain\n",
    "# 7. 降低学习率，增加迭代次数，验证模型\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}