{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 特征构建"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "特征工程代码主要分为工具函数、特征群生成函数、版本集成函数和特征生成函数，\n",
    "调用关系为特征生成函数->版本集成函数->特征群生成几乎是->工具函数。"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 工具函数\n",
    "1. 特征处理函数       计算折扣率、将满减和折扣统一、确定是否为满减优惠、获取满减的满额条件、获取满减的优惠等\n",
    "2. 统计特征生成函数    通过统计提取特征。"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# 统计特征处理函数\n",
    "# df: 添加特征的dataframe\n",
    "# df_group: 特征生成的数据集\n",
    "# group_cols: group by的列\n",
    "# value_col: 被统计的列\n",
    "# agg_ops: 处理方式 包括count, mean, sum, std, max, min, nunique\n",
    "# colname: 新特征的名称\n",
    "def add_agg_feature_names(df, df_group, group_cols, value_col, agg_ops, col_names):\n",
    "    df_group[value_col] = df_group[value_col].astype('float')\n",
    "    df_agg = pd.DataFrame(\n",
    "        df_group.groupby(group_cols)[value_col].agg(agg_ops)\n",
    "    ).reset_index()\n",
    "    df_agg.columns = group_cols + col_names\n",
    "    df = df.merge(df_agg, on=group_cols, how='left')\n",
    "    return df\n",
    "\n",
    "# 特征特征处理函数\n",
    "# 名称按照keyword + '_' + value_col + '_' + op自动增加\n",
    "def add_agg_feature(df, df_group, group_cols, value_col, agg_ops, keyword):\n",
    "    col_names = []\n",
    "    for op in agg_ops:\n",
    "        col_names.append(keyword + '_' + value_col + '_' + op)\n",
    "    df = add_agg_feature_names(df, df_group, group_cols, value_col, agg_ops, col_names)\n",
    "    return df\n",
    "\n",
    "# 因为count特征很多，所以开发列这个专门提取count特征的函数\n",
    "def add_count_new_feature(df, df_group, group_cols, new_feature_name):\n",
    "    df_group[new_feature_name] = 1\n",
    "    df_group = df_group.groupby(group_cols).agg('sum').reset_index()\n",
    "    df = df.merge(df_group, on=group_cols, how='left')\n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 特征生成函数"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# 1. 商户相关特征群\n",
    "def get_merchant_feature(feature):\n",
    "    merchant = feature[[\n",
    "        'merchant_id', 'coupon_id', 'distance', 'data_received', 'date'\n",
    "    ]].copy()\n",
    "    t = merchant[['merchant_id']].copy()\n",
    "    # 删除重复行数据\n",
    "    t.drop_duplicates(inplace=True)\n",
    "\n",
    "    # 每个商户的交易总次数\n",
    "    t1 = merchant[merchant.date != 'nan'][['merchant_id']].copy() # null -> nan\n",
    "    merchant_feature = add_count_new_feature(t, t1, 'merchant_id', 'total_sales')\n",
    "\n",
    "    # 在每个商户销售中，使用优惠券的交易次数（正样本）\n",
    "    t2 = merchant[(merchant.date != 'nan') & (merchant.coupon_id != 'nan')][['merchant_id']].copy() # null -> nan\n",
    "    merchant_feature = add_count_new_feature(merchant_feature, t2, 'merchant_id', 'sales_use_coupon')\n",
    "\n",
    "    # 每个商户发放的优惠券总数\n",
    "    t3 = merchant[merchant.coupon_id != 'nan'][['merchant_id']].copy() # null -> nan\n",
    "    merchant_feature = add_count_new_feature(merchant_feature, t3, 'merchant_id', 'total_coupon')\n",
    "\n",
    "    # 在每个线下商户含有优惠券的交易中，统计和用户距离的最大值、最小值、平均值、中位值\n",
    "    t4 = merchant[(merchant.date != 'nan') & (merchant.coupon_id != 'nan') & (merchant.distance != 'nan')][['merchant_id', 'distance']].copy() # null -> nan\n",
    "    t4.distance = t4.distance.astype('int')\n",
    "    merchant_feature = add_agg_feature(merchant_feature, t4, ['merchant_id'], 'distance', ['min', 'max', 'mean', 'median'], 'merchant')\n",
    "\n",
    "    # 将数据中的nan值用0来替换\n",
    "    merchant_feature.sales_use_coupon = merchant_feature.sales_use_coupon.replace(np.nan, 0)\n",
    "\n",
    "    # 商户发放优惠券的使用率\n",
    "    merchant_feature['merchant_coupon_transfer_rate'] = merchant_feature.sales_use_coupon.astype('float') / merchant_feature.total_sales\n",
    "\n",
    "    # 将数据中的nan值用0来替换\n",
    "    merchant_feature.total_sales = merchant_feature.total_sales.replace(np.nan, 0)\n",
    "\n",
    "    return merchant_feature"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# 2. 用户相关特征群\n",
    "def get_user_feature(feature):\n",
    "    user = feature[[\n",
    "        'user_id', 'merchant_id', 'coupon_id', 'discount_rate', 'distance', 'data_received', 'date'\n",
    "    ]].copy()\n",
    "    t = user[['user_id']].copy()\n",
    "    # 删除重复行数据\n",
    "    t.drop_duplicates(inplace=True)\n",
    "\n",
    "    # 每个用户交易的商户数\n",
    "    t1 = user[user.date != 'nan'][['user_id', 'merchant_id']].copy() # null -> nan\n",
    "    t1.drop_duplicates(inplace=True)\n",
    "    t1 = t1[['user_id']]\n",
    "    user_feature = add_count_new_feature(t, t1, 'user_id', 'count_merchant')\n",
    "\n",
    "    # 在每个用户线下使用优惠券的交易中，统计和商户户距离的最大值、最小值、平均值、中位值\n",
    "    t2 = user[(user.date != 'nan') & (user.coupon_id != 'nan') & (user.distance != 'nan')][['user_id', 'distance']].copy() # null -> nan\n",
    "    t2.distance = t2.distance.astype('int')\n",
    "    user_feature = add_agg_feature(user_feature, t2, ['user_id'], 'distance', ['min', 'max', 'mean', 'median'], 'user')\n",
    "\n",
    "    # 每个用户使用优惠券消费的次数\n",
    "    t7 = user[(user.date != 'nan') & (user.coupon_id != 'nan')][['user_id']].copy() # null -> nan\n",
    "    user_feature = add_count_new_feature(user_feature, t7, 'user_id', 'buy_use_coupon')\n",
    "\n",
    "    # 每个用户消费的总次数\n",
    "    t8 = user[user.date != 'nan'][['user_id']].copy() # null -> nan\n",
    "    user_feature = add_count_new_feature(user_feature, t8, 'user_id', 'buy_total')\n",
    "\n",
    "    # 每个用户收到优惠券的总数\n",
    "    t9 = user[user.coupon_id != 'nan'][['user_id']].copy() # null -> nan\n",
    "    user_feature = add_count_new_feature(user_feature, t9, 'user_id', 'coupon_received')\n",
    "\n",
    "    # 用户从收到优惠券到用券消费的时间间隔，统计其最大值、最小值、平均值、中位值\n",
    "    t10 = user[(user.date != 'nan') & (user.date_received != 'nan')][['user_id', 'date_received', 'date']].copy() # null -> nan\n",
    "    t10 = add_day_gap(t10)\n",
    "    t10 = t10[['user_id', 'day_gap']]\n",
    "    user_feature = add_agg_feature(user_feature, t10, ['user_id'], 'day_gap', ['min', 'max', 'mean', 'median'], 'user')\n",
    "\n",
    "    # 统计用户用券消费在总消费中的占比\n",
    "    user_feature['buy_use_coupon_rate'] = user_feature.buy_use_coupon.astype('float') / user_feature.buy_total.astype('float')\n",
    "\n",
    "    # 统计用户收到消费券的使用率\n",
    "    user_feature['user_coupon_transfer_rate'] = user_feature.buy_use_coupon.astype('float') / user_feature.coupon_received.astype('float')\n",
    "\n",
    "    # 将数据中的nan值用0来替换\n",
    "    user_feature.buy_total = user_feature.buy_total.replace(np.nan, 0)\n",
    "    user_feature.coupon_received = user_feature.coupon_received.replace(np.nan, 0)\n",
    "\n",
    "    return user_feature"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# 用户和商户关系特征群\n",
    "def get_user_merchant_feature(feature):\n",
    "    t = feature[['user_id', 'merchant_id']].copy()\n",
    "    # 删除重复行数据\n",
    "    t.drop_duplicates(inplace=True)\n",
    "\n",
    "    # 一个用户在一个商家一共交易的总次数\n",
    "    t0 = feature[['user_id', 'merchant_id', 'date']].copy()\n",
    "    t0 = t0[t0.date != 'nan'][['user_id', 'merchant_id']] # null -> nan\n",
    "    user_merchant = add_count_new_feature(t, t0, ['user_id', 'merchant_id'], 'user_merchant_buy_total')\n",
    "\n",
    "    # 一个用户在一个商家一共收到的优惠券数量\n",
    "    t1 = feature[['user_id', 'merchant_id', 'coupon_id']].copy()\n",
    "    t1 = t1[t1.coupon_id != 'nan'][['user_id', 'merchant_id']] # null -> nan\n",
    "    user_merchant = add_count_new_feature(user_merchant, t1, ['user_id', 'merchant_id'], 'user_merchant_received')\n",
    "\n",
    "    # 一个用户在一个商家使用优惠券消费的次数\n",
    "    t2 = feature[['user_id', 'merchant_id', 'date', 'date_received']].copy()\n",
    "    t2 = t2[(t2.date != 'nan') & (t2.date_received != 'nan')][['user_id', 'merchant_id']] # null -> nan\n",
    "    user_merchant = add_count_new_feature(user_merchant, t2, ['user_id', 'merchant_id'], 'user_merchant_buy_use_coupon')\n",
    "\n",
    "    # 一个用户在一个商家的到店次数\n",
    "    t3 = feature[['user_id', 'merchant_id']].copy()\n",
    "    user_merchant = add_count_new_feature(user_merchant, t3, ['user_id', 'merchant_id'], 'user_merchant_any')\n",
    "\n",
    "    # 一个用户在一个商家没有使用优惠券消费的次数\n",
    "    t4 = feature[['user_id', 'merchant_id', 'date', 'coupon_id']].copy()\n",
    "    t4 = t4[(t4.date != 'nan') & (t4.coupon_id != 'nan')][['user_id', 'merchant_id']] # null -> nan\n",
    "    user_merchant = add_count_new_feature(user_merchant, t4, ['user_id', 'merchant_id'], 'user_merchant_buy_common')\n",
    "\n",
    "    # 将数据中的nan值用0来替换\n",
    "    user_merchant.user_merchant_buy_use_coupon = user_merchant.user_merchant_buy_use_coupon.replace(np.nan, 0)\n",
    "    user_merchant.user_merchant_buy_common = user_merchant.user_merchant_buy_common.replace(np.nan, 0)\n",
    "\n",
    "    # 一个用户对一个商家发放优惠券的使用率\n",
    "    user_merchant['user_merchant_coupon_transfer_rate'] = user_merchant.user_merchant_buy_use_coupon.astype('float') / user_merchant.user_merchant_received.astype('float')\n",
    "\n",
    "    # 一个用户在一个商家的总消费次数中，用消费券消费次数占比\n",
    "    user_merchant['user_merchant_coupon_buy_rate'] = user_merchant.user_merchant_buy_use_coupon.astype('float') / user_merchant.user_merchant_buy_total.astpye('float')\n",
    "\n",
    "    # 一个用户到店后消费的可能性统计\n",
    "    user_merchant['user_merchant_rate'] = user_merchant.user_merchant_buy_total.astype('float') / user_merchant.user_merchant_any.astpye('float')\n",
    "\n",
    "    # 一个用户在一个商家的在消费次数中，不用优惠券的消费次数占比\n",
    "    user_merchant['user_merchant_common_buy_rate'] = user_merchant.user_merchant_buy_common.astype('float') / user_merchant.user_merchant_buy_total.astpye('float')\n",
    "\n",
    "    return user_merchant"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# 4. Leakage特征群\n",
    "def get_leakage_feature(dataset):\n",
    "    t = dataset[['user_id']].copy()\n",
    "    t['this_month_user_received_all_coupon_count'] = 1\n",
    "    t = t.groupby('user_id').agg('sum').reset_index()\n",
    "    t1 = dataset[['user_id', 'coupon_id']].copy()\n",
    "    t1['this_month_user_received_same_coupon_count'] = 1\n",
    "    t1 = t1.groupby(['user_id', 'coupon_id']).agg('sum').reset_index()\n",
    "    t2 = dataset[['user_id', 'coupon_id', 'date_received']].copy()\n",
    "    t2.date_received = t2.date_received.astype('str')\n",
    "    # 如果出现相同的用户接收相同的优惠券，则在接收时间上用':'连接上第n次接受优惠券的时间\n",
    "    t2 = t2.groupby(['user_id', 'coupon_id'])['date_received'].agg(lambda x: ':'.join(x)).reset_index()\n",
    "\n",
    "    # 将接收时间的一组按':'分开，这样就可以计算所接收优惠券的数量\n",
    "    t2['receive_number'] = t2.date_received.apply(lambda s: len(s.split(':')))\n",
    "    t2 = t2[t2.receive_number > 1]\n",
    "\n",
    "    # 最大接收的日期\n",
    "    t2['max_date_received'] = t2.date_received.apply(lambda s: max([int(d) for d in s.split(':')]))\n",
    "\n",
    "    # 最小接收的日期\n",
    "    t2['min_date_received'] = t2.date_received.apply(lambda s: min([int(d) for d in s.split(':')]))\n",
    "\n",
    "    t3 = dataset[['user_id', 'coupon_id', 'date_received']].copy()\n",
    "    # 将两个表融合只保留左表数据，相当于保留了最近接收时间和最远接收时间\n",
    "    t3 = pd.merge(t3, t2, on=['user_id', 'coupon_id'], how='left')\n",
    "    # 这个优惠券最近接收时间\n",
    "    t3['this_month_user_received_same_coupon_lastone'] = t3.max_date_received - t3.date_received.astype(int)\n",
    "    # 这个优惠券最远接收时间\n",
    "    t3['this_month_user_received_same_coupon_firstone'] = t3.date_received.astype(int) - t3.min_date_received\n",
    "    t3.this_month_user_received_same_coupon_lastone = t3.this_month_user_received_same_coupon_lastone.apply(is_firstlastone)\n",
    "    t3.this_month_user_received_same_coupon_firstone = t3.this_month_user_received_same_coupon_firstone.apply(is_firstlastone)\n",
    "    t3 = t3[[\n",
    "        'user_id', 'coupon_id', 'date_received',\n",
    "        'this_month_user_received_same_coupon_lastone',\n",
    "        'this_month_user_received_same_coupon_firstone'\n",
    "    ]]\n",
    "\n",
    "    # 提取第四个特征，一个用户所接收到的所有优惠券的数量\n",
    "    t4 = dataset[['user_id', 'date_received']].copy()\n",
    "    t4['this_day_receive_all_coupon_count'] = 1\n",
    "    t4 = t4.groupby(['user_id', 'date_received']).agg('sum').reset_index()\n",
    "\n",
    "    # 提取第五个特征，一个用户不同时间所接收到的不同优惠券的数量\n",
    "    t5 = dataset[['user_id', 'coupon_id', 'date_received']].copy()\n",
    "    t5['this_day_receive_same_coupon_count'] = 1\n",
    "    t5 = t5.groupby(['user_id', 'coupon_id', 'date_received']).agg('sum').reset_index()\n",
    "\n",
    "    # 一个用户不同优惠券的接收时间\n",
    "    t6 = dataset[['user_id', 'coupon_id', 'date_received']].copy()\n",
    "    t6.date_received = t6.date_received.astype('str')\n",
    "    t6 = t6.groupby(['user_id', 'coupon_id'])['date_received'].agg(lambda x: ':'.join(x)).reset_index()\n",
    "    t6.rename(columns={'date_received': 'dates'}, inplace=True)\n",
    "\n",
    "    t7 = dataset[['user_id', 'coupon_id', 'date_received']].copy()\n",
    "    t7 = pd.merge(t7, t6, on=['user_id', 'coupon_id'], how='left')\n",
    "    t7['date_received_date'] = t7.date_received.astype('str') + '-' + t7.dates\n",
    "    t7['day_gap_before'] = t7.date_received_date.apply(get_day_gap_before)\n",
    "    t7['day_gap_after'] = t7.date_received_date.apply(get_day_gap_after)\n",
    "    t7 = t7[[\n",
    "        'user_id', 'coupon_id', 'date_received', 'day_gap_before', 'day_gap_after'\n",
    "    ]]\n",
    "\n",
    "    other_feature = pd.merge(t1, t, on='user_id')\n",
    "    other_feature = pd.merge(other_feature, t3, on=['user_id', 'coupon_id'])\n",
    "    other_feature = pd.merge(other_feature, t4, on=['user_id', 'date_received'])\n",
    "    other_feature = pd.merge(other_feature, t5, on=['user_id', 'coupon_id', 'date_received'])\n",
    "    other_feature = pd.merge(other_feature, t7, on=['user_id', 'coupon_id', 'date_received'])\n",
    "\n",
    "    return other_feature"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 特征集成函数"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# 特征版本1\n",
    "def f1(dataset, if_train):\n",
    "    result = add_discount(dataset)\n",
    "    result.drop_duplicates(inplace=True)\n",
    "    if if_train:\n",
    "        result = add_label(result)\n",
    "    return result"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "# 特征版本2\n",
    "def f2(dateset, feature, if_train):\n",
    "    result = add_discount(dataset)\n",
    "    merchant_feature = get_merchant_feature(feature)\n",
    "    result = result.merge(merchant_feature, on='merchant_id', how='left')\n",
    "    user_feature = get_user_feature(feature)\n",
    "    result = result.merge(user_feature, on='user_id', how='left')\n",
    "    user_merchant = get_user_merchant_feature(feature)\n",
    "    result = result.merge(user_merchant, on=['user_id', 'merchant_id'], how='left')\n",
    "\n",
    "    result.drop_duplicates(inplace=True)\n",
    "    if if_train:\n",
    "        result = add_label(result)\n",
    "    return result"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "# 特征版本3\n",
    "def f3(dataset, feature, if_train):\n",
    "    result = add_discount(dataset)\n",
    "    merchant_feature = get_merchant_feature(feature)\n",
    "    result = result.merge(merchant_feature, on='merchant_id', how='left')\n",
    "    user_feature = get_user_feature(feature)\n",
    "    result = result.merge(user_feature, on='user_id', how='left')\n",
    "    user_merchant = get_user_merchant_feature(feature)\n",
    "    result = result.merge(user_merchant, on=['user_id', 'merchant_id'], how='left')\n",
    "    leakage_feature = get_leakage_feature(dataset)\n",
    "    result = result.merge(leakage_feature, on=['user_id', 'coupon_id', 'date_received'], how='left')\n",
    "\n",
    "    result.drop_duplicates(inplace=True)\n",
    "    if if_train:\n",
    "        result = add_label(result)\n",
    "    return result"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 特征输出"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "# 1. 未使用滑窗的情况\n",
    "def normal_feature_generate(feature_function):\n",
    "    off_train = pd.read_csv(datapath + 'ccf_offline_stage1_train.csv', header=0, keep_default_na=False)\n",
    "    off_train.columns = [\n",
    "        'user_id', 'merchant_id', 'coupon_id', 'discount_rate', 'distance', 'date_received', 'date'\n",
    "    ]\n",
    "    off_test = pd.read_csv(datapath + 'ccf_offline_stage1_test_revised.csv', header=0, keep_default_na=False)\n",
    "    off_test.columns = [\n",
    "        'user_id', 'merchant_id', 'coupon_id', 'discount_rate', 'distance', 'date_received'\n",
    "    ]\n",
    "\n",
    "    # 取时间大于20160501是为了减少数据量，模型算的快一点\n",
    "    # 如果时间足够，可以不加这个限制\n",
    "    off_train = off_train[(off_train.coupon_id != 'nan') & (off_train.date_received != 'nan') & (off_train.date_received >= '20160501')]\n",
    "    dftrain = feature_function(off_train, True)\n",
    "    dftest = feature_function(off_test, False)\n",
    "\n",
    "    dftrain.drop(['date'], axis=1, inplace=True)\n",
    "    dftrain.drop(['merchant_id'], axis=1, inplace=True)\n",
    "    dftest.drop(['merchant_id'], axis=1, inplace=True)\n",
    "\n",
    "    # 输出特征\n",
    "    print('输出特征')\n",
    "    dftrain.to_csv(featurepath + 'train_' + feature_function.__name__ + '.csv', index=False, sep=',')\n",
    "    dftest.to_csv(featurepath + 'test_' + feature_function.__name__ + '.csv', index=False, sep=',')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "# 2. 使用滑窗的情况\n",
    "def slide_feature_generate(feature_function):\n",
    "    off_train = pd.read_csv(datapath + 'ccf_offline_stage1_train.csv', header=0, keep_default_na=False)\n",
    "    off_train.columns = [\n",
    "        'user_id', 'merchant_id', 'coupon_id', 'discount_rate', 'distance', 'date_received', 'date'\n",
    "    ]\n",
    "    off_test = pd.read_csv(datapath + 'ccf_offline_stage1_test_revised.csv', header=0, keep_default_na=False)\n",
    "    off_test.columns = [\n",
    "        'user_id', 'merchant_id', 'coupon_id', 'discount_rate', 'distance', 'date_received'\n",
    "    ]\n",
    "\n",
    "    # 交叉训练集一：收到券的日期大于4月14日且小于5月14日\n",
    "    dataset1 = off_train[(off_train.date_received >= '20160414') &\n",
    "                         (off_train.date_received <= '20160514')]\n",
    "    # 交叉训练集一特征：线下数据中领券和用券日期大于1月1日且小于4月1日\n",
    "    feature1 = off_train[(off_train.date >= '20160101') &\n",
    "                         (off_train.date <= '20160413') |\n",
    "                         ((off_train.date == 'nan') &\n",
    "                         (off_train.date_received >= '20160101') &\n",
    "                         (off_train.date_received <= '20160413'))]\n",
    "\n",
    "    # 交叉训练集二：收到券的日期大于5月15日且小于6月15日\n",
    "    dataset2 = off_train[(off_train.date_received >= '20160515') &\n",
    "                         (off_train.date_received <= '20160615')]\n",
    "    # 交叉训练集二特征：线下数据中领券和用券日期大于2月1日且小于5月14日\n",
    "    feature2 = off_train[(off_train.date >= '20160201') &\n",
    "                         (off_train.date <= '20160514') |\n",
    "                         ((off_train.date == 'nan') &\n",
    "                         (off_train.date_received >= '20160201') &\n",
    "                         (off_train.date_received <= '20160514'))]\n",
    "\n",
    "    # 测试集\n",
    "    dataset3 = off_test\n",
    "    # 测试集特征：线下数据中领券和用券日期大于3月15日且小于6月30日\n",
    "    feature3 = off_train[(off_train.date >= '20160315') &\n",
    "                         (off_train.date <= '20160630') |\n",
    "                         ((off_train.date == 'nan') &\n",
    "                         (off_train.date_received >= '20160315') &\n",
    "                         (off_train.date_received <= '20160630'))]\n",
    "\n",
    "    dftrain1 = feature_function(dataset1, feature1, True)\n",
    "    dftrain2 = feature_function(dataset2, feature2, True)\n",
    "    dftrain = pd.concat(dftrain1, dftrain2, axis=0)\n",
    "    dftest = feature_function(dataset3, feature3, False)\n",
    "\n",
    "    dftrain.drop(['date'], axis=1, inplace=True)\n",
    "    dftrain.drop(['merchant_id'], axis=1, inplace=True)\n",
    "    dftest.drop(['merchant_id'], axis=1, inplace=True)\n",
    "\n",
    "    # 输出特征\n",
    "    print('输出特征')\n",
    "    dftrain.to_csv(featurepath + 'train_s' + feature_function.__name__ + '.csv', index=False, sep=',')\n",
    "    dftest.to_csv(featurepath + 'test_s' + feature_function.__name__ + '.csv', index=False, sep=',')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'datapath' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-22-65ceb778856b>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[0;31m# 生成特征文件\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 3\u001B[0;31m \u001B[0mnormal_feature_generate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mf1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      4\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0mslide_feature_generate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mf2\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-18-d028342e61da>\u001B[0m in \u001B[0;36mnormal_feature_generate\u001B[0;34m(feature_function)\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[0;31m# 1. 未使用滑窗的情况\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0;32mdef\u001B[0m \u001B[0mnormal_feature_generate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfeature_function\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 4\u001B[0;31m     \u001B[0moff_train\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mread_csv\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdatapath\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0;34m'ccf_offline_stage1_train.csv'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mheader\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkeep_default_na\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mFalse\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      5\u001B[0m     off_train.columns = [\n\u001B[1;32m      6\u001B[0m         \u001B[0;34m'user_id'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'merchant_id'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'coupon_id'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'discount_rate'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'distance'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'date_received'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'date'\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'datapath' is not defined"
     ]
    }
   ],
   "source": [
    "# 生成特征文件\n",
    "normal_feature_generate(f1)\n",
    "\n",
    "slide_feature_generate(f2)\n",
    "\n",
    "slide_feature_generate(f3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 对特征进行探索"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 特征读取函数"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "id_col_names = ['user_id', 'coupon_id', 'date_received']\n",
    "target_col_name = 'label'\n",
    "id_target_cols = ['user_id', 'coupon_id', 'date_received', 'label']\n",
    "\n",
    "# 返回ID列\n",
    "def get_id_df(df):\n",
    "    return df[id_col_names]\n",
    "\n",
    "# 返回target列\n",
    "def get_target_df(df):\n",
    "    return df[target_col_name]\n",
    "\n",
    "# 返回特征列\n",
    "def get_predictors_df(df):\n",
    "    predictors = [f for f in df.columns if f not in id_target_cols]\n",
    "    return df[predictors]\n",
    "\n",
    "# 按特征名读取训练集\n",
    "def read_featurefile_train(featurename):\n",
    "    df = pd.read_csv(featurepath + 'train_' + featurename + '.csv', sep=',', encoding='utf-8')\n",
    "    return df\n",
    "\n",
    "# 按特征名读取测试集\n",
    "def read_featurefile_test(featurename):\n",
    "    df = pd.read_csv(featurepath + 'test_' + featurename + '.csv', sep=',', encoding='utf-8')\n",
    "    return df\n",
    "\n",
    "# 按特征名读取数据\n",
    "def read_data(featurename):\n",
    "    traindf = read_featurefile_train(featurename)\n",
    "    testdf = read_featurefile_test(featurename)\n",
    "    return traindf, testdf"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'featurepath' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-24-488369913ab4>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[0;31m# 特征总览\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 3\u001B[0;31m \u001B[0mtraindf\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtestdf\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mread_data\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'sf3'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      4\u001B[0m \u001B[0mtrain_X\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mget_predictors_df\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtraindf\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0mtrain_y\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mget_target_df\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtraindf\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-21-02abafe8877d>\u001B[0m in \u001B[0;36mread_data\u001B[0;34m(featurename)\u001B[0m\n\u001B[1;32m     29\u001B[0m \u001B[0;31m# 按特征名读取数据\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     30\u001B[0m \u001B[0;32mdef\u001B[0m \u001B[0mread_data\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfeaturename\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 31\u001B[0;31m     \u001B[0mtraindf\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mread_featurefile_train\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfeaturename\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     32\u001B[0m     \u001B[0mtestdf\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mread_featurefile_test\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfeaturename\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     33\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0mtraindf\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtestdf\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-21-02abafe8877d>\u001B[0m in \u001B[0;36mread_featurefile_train\u001B[0;34m(featurename)\u001B[0m\n\u001B[1;32m     19\u001B[0m \u001B[0;31m# 按特征名读取训练集\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     20\u001B[0m \u001B[0;32mdef\u001B[0m \u001B[0mread_featurefile_train\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfeaturename\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 21\u001B[0;31m     \u001B[0mdf\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mread_csv\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfeaturepath\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0;34m'train_'\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0mfeaturename\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0;34m'.csv'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msep\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m','\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mencoding\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'utf-8'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     22\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0mdf\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     23\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'featurepath' is not defined"
     ]
    }
   ],
   "source": [
    "# 特征总览\n",
    "traindf, testdf = read_data('sf3')\n",
    "train_X = get_predictors_df(traindf)\n",
    "train_y = get_target_df(traindf)\n",
    "test_X = get_predictors_df(testdf)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'traindf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-25-07e0f02f1203>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m \u001B[0mtraindf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdescribe\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m: name 'traindf' is not defined"
     ]
    }
   ],
   "source": [
    "traindf.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'testdf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-26-e6d6d3115fc6>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m \u001B[0mtestdf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdescribe\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m: name 'testdf' is not defined"
     ]
    }
   ],
   "source": [
    "testdf.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 查看特征的分布\n",
    "# 箱线图\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "column = train_X.columns.tolist()[:46]\n",
    "fig = plt.figure(figsize=(20, 40))\n",
    "for i in range(45):\n",
    "    plt.subplot(15, 3, i + 1)\n",
    "    sns.boxplot(data=train_X[column[i]], orient='v', width=0.5)\n",
    "    plt.ylabel(column[i], fontsize=8)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "column = test_X.columns.tolist()[:46]\n",
    "fig = plt.figure(figsize=(20, 40))\n",
    "for i in range(45):\n",
    "    plt.subplot(15, 3, i + 1)\n",
    "    sns.boxplot(data=test_X[column[i]], orient='v', width=0.5)\n",
    "    plt.ylabel(column[i], fontsize=8)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 对比offline训练集和测试集的特征分布情况\n",
    "dist_cols = 4\n",
    "dist_rows = len(test_X.columns)\n",
    "\n",
    "plt.figure(figsize=(4 * dist_cols, 4 * dist_rows))\n",
    "\n",
    "for i, col in enumerate(test_X.columns):\n",
    "    ax = plt.subplot(dist_rows, dist_cols, i + 1)\n",
    "    ax = sns.kdeplot(train_X[col], color='Red', shade=True)\n",
    "    ax = sns.kdeplot(test_X[col], color='Blue', shade=True)\n",
    "    ax.set_xlabel(col)\n",
    "    ax.set_ylabel('Frequency')\n",
    "    ax = ax.legend(['train', 'test'])\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_X_fd1 = train_X[train_X.if_fd == 1].reset_index(drop=True)\n",
    "test_X_fd1 = test_X[test_X.if_fd == 1].reset_index(drop=True)\n",
    "dist_cols = 4\n",
    "dist_rows = len(test_X_fd1.columns)\n",
    "\n",
    "plt.figure(figsize=(4 * dist_cols, 4 * dist_rows))\n",
    "\n",
    "for i, col in enumerate(test_X_fd1.columns):\n",
    "    ax = plt.subplot(dist_rows, dist_cols, i + 1)\n",
    "    ax = sns.kdeplot(train_X_fd1[col], color='Red', shade=True)\n",
    "    ax = sns.kdeplot(test_X_fd1[col], color='Blue', shade=True)\n",
    "    ax.set_xlabel(col)\n",
    "    ax.set_ylabel('Frequency')\n",
    "    ax = ax.legend(['train', 'test'])\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 特征相关性分析\n",
    "plt.figure(figsize=(20, 16))\n",
    "columns = traindf.columns.tolist()\n",
    "mcorr = traindf[column].corr(method='spearman')\n",
    "mask = np.zeros_like(mcorr, dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "g = sns.heatmap(mcorr,\n",
    "                mask=mask,\n",
    "                cmap=cmap,\n",
    "                square=True,\n",
    "                annot=True,\n",
    "                fmt='0.2f')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}