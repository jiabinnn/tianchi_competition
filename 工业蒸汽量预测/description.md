# 工业蒸汽量预测

#### 数据说明

V0-V37共38个字段是特征变量，target字段是目标变量。

测试集没有target字段。

#### 评估指标

均方误差$MSE(Mean Squared Error)$
$$
MSE=\frac{SSE}{n}=\frac{1}{n}\sum_{i=1}^{n}(y-\hat{y})^2
$$




#### 模型

1. 线性回归(Linear Regression)
2. 岭回归(Ridge Regression)
3. LASSP(Least Absolute Shrinkage and Selection Opterator)回归
4. 决策树回归(Decision Tree Regressor)
5. 梯度提升树回归(Gradient Boosting Decision Tree Regressor)



## 数据探索

#### 变量分析

##### 单变量分析

- Histogram

- Box Plot

##### 双变量分析

1. 连续型与连续型
   - 散点图
   - 相关性
2. 类别型与类别型
   - 双向表
   - 堆叠柱状图
   - 卡方检验：主要用于两个和两个以上样本率及两个二值型离散变量的关联性分析，即比较理论频次和实际频次的吻合程度或拟合优度。
3. 类别型与连续型
   - 小提琴图，分析不同类别时，另一个连续变量的分布情况。

#### 缺失值处理

1. 删除。成列删除，成对删除
2. 平均数、众数、中值填充
3. 预测模型填充

#### 异常值处理

##### 异常值的检测

- 箱线图、直方图、散点图

##### 异常值的处理

- 删除、转换、填充、区别对待

数据取对数会减轻由极值引起的变化



#### 可视化数据分布

- 箱形图
- 直方图和QQ图
- KDE分布图：核密度估计，可以理解为对直方图的加窗平滑。通过绘制KDE图可以查看并对比训练集和测试集中特征变量的分布情况，发现两个数据集中分布不一致的特征变量。**删除训练集和测试集中分布不一致的特征，否则会导致模型泛化能力变差**
- 线性回归关系图：查看变量与target之间的线性回归关系

#### 查看特征变量的相关性

1. 计算相关系数

2. 相关热力图

3. 根据相关系数筛选特征变量
4. Box-Cox变换：可以使线性模型在满足线性、正态性、独立性及方差齐性的同时，又不丢失信息。



## 3. 特征工程

### 3.1. 特征工程的重要性

1. 特征越好，灵活性越强
2. 特征越好，构建的模型月简单
3. 特征越好，模型的性能月出色

### 3.2. 数据预处理和特征处理

#### 3.2.1 数据预处理

1. ##### 数据采集

2. ##### 数据清洗

3. ##### 数据采样

#### 3.2.2 特征处理

1. 标准化
2. 区间缩放法
3. 归一化
4. 定量特征二值化(threshold阈值)
5. 定性特征哑编码(OneHot)
6. 缺失值处理
7. 数据转换
   - 多项式转换
   - 指数、对数变换

### 3.3 特征降维

#### 3.3.1 特征选择

- 特征选择的方法
  1. 过滤法 Filter 按照发散性和相关性对特征进行评分，设定阈值选择特征。
     - 方差选择法
     - 相关系数、卡方检验或最大信息系数作为得分计算的方法
  2. 包装法 Wrapper 根据目标函数（通常是预测效果评分）每次选择若干特征，或者排除若干特征。
  3. 嵌入法 Embedded 使用机器学习的某些算法和模型进行训练，得到每个特在的权值系数，根据系数从大到小选择特征。

#### 3.3.2 线性降维

1. 主成分分析
2. 线性判别分析

### 3.4 赛题特征工程

#### 3.4.1 异常值分析

#### 3.4.2 最大最小的归一化

#### 3.4.3 KDE查看数据分布

#### 3.4.4 特征相关性

#### 3.4.5 特征降维

#### 3.4.6 多重共线性分析

- 多重共线性分析的原则是特征组之间的相关性系数较大，即每个特征变量与其他特征变量之间的相关性系数较大，故可能存在较大的共线性影响，这会导致模型估计不准。因此，后续要使用PCA对数据进行处理，去除多重共线性。

#### 3.4.7 PCA处理

- 利用PCA的方法去除数据的多重共线性，并进行降维。PCA处理后可保持90%的信息数据。