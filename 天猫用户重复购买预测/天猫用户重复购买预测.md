# 天猫用户重复购买预测

## 2 数据探索

### 2.1 理论知识

#### 2.1.1 缺失值处理

1. 缺失值产生的原因：比如人为或者计算机未能收集到
2. 发现缺失数据：Pandas的count()可以统计不为空数据的个数，shape()可以统计数据样本的个数，将shape和count做差就可以得到数据的缺失个数。

3. 缺失值处理

   - 统计量填充 

     连续值：中位数

     离散值：众数，不可用均值和中位数

   - 特殊值填充

     填一个不在正常范围内的数值表示缺失值

   - 不处理：XGB和LGB对缺失值并不敏感，算法本身有一套缺失值处理算法

   常用的缺失值填补方法 P138

   1. 类均值插补
   2. 类随机插补
   3. 回归插补
   4. Em插补
   5. 多重插补MCMC

#### 2.1.2 不均匀样本

1. 随机欠采样
2. 随机过采样
3. 基于聚类的过采样方法
4. SMOTE算法
5. 基于数据清洗SMOTE

#### 2.1.3 常见的数据分布

1. 伯努利分布，0-1分布

$$
P(X=x)=\begin{cases} 1-p & x=0 \\ p & x=1\end{cases}
$$

2. 二项分布，n次独立的0-1分布

$$
P(X=x)= \frac{n!}{(n-x)!x!}p^xq^{n-x}
$$

3. 泊松分布

$$
P(X=x)=e^{-\mu}\frac{\mu^x}{x!}
$$

4. 正态分布

$$
f(x)=\frac{1}{\sqrt{2\pi}\sigma}exp\left(-\frac{(x-\mu)^2}{2\sigma^2}\right) (-\infty < x < +\infty)
$$

5. 指数分布

$$
f(x)=\begin{cases} \lambda e^{-\lambda_x}, & x>0 \\ 0, & x \le 0\end{cases}
$$

# 3 特征工程

### 3.1 特征工程介绍

#### 3.1.2 特征归一化

1. 线性函数归一化
2. 零均值归一化

#### 3.1.3 类别特征的转换

- 序号编码
- 独热编码
- 二进制编码

#### 3.1.4 高维组合特征的处理

把一阶离散特征两两组合，就构成了高阶组合特征

#### 3.1.5 组合特征

简单的将特征两两组合容易存在参数过多、过拟合等问题，此时可以引入决策树方法来组合特征。

#### 3.1.6 文本表示模型

1. **词袋模型**

$$
TF.IDF = TF(t,d)*IDF(t), IDF=log\frac a{b+1}
$$

​	$TF(t,d)$为单词t在文档d中出现的频率，$a$=文章总数，$b$=包含单词的文章总数

2. **N-gram模型**

3. **主题模型**

4. **词嵌入**

