{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "train_data = pd.read_csv('./dataset/train_all.csv', nrows=None)\n",
    "test_data = pd.read_csv('./dataset/test_all.csv', nrows=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "features_columns = [col for col in train_data.columns if col not in ['user_id', 'label']]\n",
    "train = train_data[features_columns].values\n",
    "test = test_data[features_columns].values\n",
    "target = train_data['label'].values"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1200, 227) (1200,)\n",
      "(800, 227) (800,)\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.9275"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100,\n",
    "                             max_depth=2,\n",
    "                             random_state=0,\n",
    "                             n_jobs=-1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(train, target, test_size=0.4, random_state=0)\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)\n",
    "\n",
    "clf = clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 简单验证"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "clf = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=2,\n",
    "    random_state=0, n_jobs=-1\n",
    ")\n",
    "scores = cross_val_score(clf, train, target, cv=5)\n",
    "print(scores)\n",
    "print('Accuracy : %.2f' % scores.mean())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.48387097 0.48320413 0.48320413 0.48320413 0.48320413]\n",
      "Accuracy : 0.48\n"
     ]
    }
   ],
   "source": [
    "# F1值评价模型\n",
    "from sklearn import metrics\n",
    "clf = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=2,\n",
    "    random_state=0, n_jobs=-1\n",
    ")\n",
    "scores = cross_val_score(clf, train, target, cv=5, scoring='f1_macro')\n",
    "print(scores)\n",
    "print('Accuracy : %.2f' % scores.mean())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 交叉验证"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#使用ShuffleSplit切分数据\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "clf = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=2,\n",
    "    random_state=0, n_jobs=-1\n",
    ")\n",
    "cv = ShuffleSplit(n_splits=5, test_size=0.3, random_state=0)\n",
    "scores = cross_val_score(clf, train, target, cv=cv)\n",
    "print(scores)\n",
    "print('Accuracy : %.2f' % scores.mean())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k, Accuracy : 0.94\n",
      "k, Accuracy : 0.93\n",
      "k, Accuracy : 0.94\n",
      "k, Accuracy : 0.93\n",
      "k, Accuracy : 0.95\n"
     ]
    }
   ],
   "source": [
    "# 使用KFold切分数据\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "clf = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=2,\n",
    "    random_state=0, n_jobs=-1\n",
    ")\n",
    "kf = KFold(n_splits=5)\n",
    "for k, (train_index, test_index) in enumerate(kf.split(train)):\n",
    "    X_train, X_test, y_train, y_test = train[train_index], train[test_index], target[train_index], target[test_index]\n",
    "    clf = clf.fit(X_train, y_train)\n",
    "    scores = clf.score(X_test, y_test)\n",
    "    # print(scores)\n",
    "    print('k, Accuracy : %.2f' % scores.mean())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# 使用StratifiedKFold切分数据"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 模型调参"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for precision\n",
      "\n",
      "Best parameters set found on development set:\n",
      "{'n_estimators': 200}\n",
      "\n",
      "Grid scores on development set:\n",
      "0.572 (+/-0.201 for {'n_estimators': 50}\n",
      "0.572 (+/-0.200 for {'n_estimators': 100}\n",
      "0.622 (+/-0.200 for {'n_estimators': 200}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sunjiabin/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train, target, test_size=0.5, random_state=0)\n",
    "\n",
    "clf = RandomForestClassifier(n_jobs=-1)\n",
    "\n",
    "tuned_params = {\n",
    "    'n_estimators': [50,100,200],\n",
    "\n",
    "}\n",
    "scores = ['precision']\n",
    "for score in scores:\n",
    "    print('# Tuning hyper-parameters for %s' % score)\n",
    "    print()\n",
    "\n",
    "    clf = GridSearchCV(clf, tuned_params, cv=5, scoring='%s_macro' % score)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    print('Best parameters set found on development set:')\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print('Grid scores on development set:')\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, param in zip(means, stds, clf.cv_results_['params']):\n",
    "        print('%0.3f (+/-%0.03f for %r' % (mean, std, param))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 混淆矩阵"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix, without normalization\n",
      "[[459   8]\n",
      " [ 31   2]]\n",
      "normalized confusion matrix\n",
      "[[0.98 0.02]\n",
      " [0.94 0.06]]\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 2 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 2 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "class_names = ['no-repeat', 'repeat']\n",
    "X_train, X_test, y_train, y_test = train_test_split(train, target, random_state=0)\n",
    "clf = RandomForestClassifier(n_jobs=-1)\n",
    "y_pred = clf.fit(X_train, y_train).predict(X_test)\n",
    "\n",
    "def plot_confusion_matrix(cm,\n",
    "                          classes,\n",
    "                          normalize=False,\n",
    "                          title='confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print('normalized confusion matrix')\n",
    "    else:\n",
    "        print('confusion matrix, without normalization')\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j,\n",
    "                 i,\n",
    "                 format(cm[i,j], fmt),\n",
    "                 horizontalalignment='center',\n",
    "                 color='white' if cm[i, j] > thresh else 'black')\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n",
    "\n",
    "cnf_matrix = confusion_matrix(y_test, y_pred)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix,\n",
    "                      classes=class_names,\n",
    "                      title='confusion matrix, without normalization')\n",
    "\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix,\n",
    "                      classes=class_names,\n",
    "                      normalize=True,\n",
    "                      title='normalized confusion matrix')\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   no-repeat       0.94      0.99      0.96       467\n",
      "      repeat       0.14      0.03      0.05        33\n",
      "\n",
      "    accuracy                           0.92       500\n",
      "   macro avg       0.54      0.51      0.51       500\n",
      "weighted avg       0.88      0.92      0.90       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class_names = ['no-repeat', 'repeat']\n",
    "X_train, X_test, y_train, y_test = train_test_split(train, target, random_state=0)\n",
    "clf = RandomForestClassifier(n_jobs=-1)\n",
    "y_pred = clf.fit(X_train, y_train).predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred, target_names=class_names))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 不同的分类模型"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sunjiabin/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.906"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. 逻辑回归\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "stdscaler = StandardScaler()\n",
    "X = stdscaler.fit_transform(train)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, target, random_state=0)\n",
    "clf = LogisticRegression(random_state=0, solver='lbfgs', multi_class='multinomial').fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "0.924"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. KNN模型\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "stdscaler = StandardScaler()\n",
    "X = stdscaler.fit_transform(train)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, target, random_state=0)\n",
    "clf = KNeighborsClassifier(n_neighbors=3).fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "0.436"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. 高斯贝叶斯模型\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "stdscaler = StandardScaler()\n",
    "X = stdscaler.fit_transform(train)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, target, random_state=0)\n",
    "clf = GaussianNB().fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "0.874"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4. 决策树模型\n",
    "from sklearn import tree\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train, target, random_state=0)\n",
    "clf = tree.DecisionTreeClassifier().fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "0.934"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5. Bagging模型\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train, target, random_state=0)\n",
    "clf = BaggingClassifier(KNeighborsClassifier(), max_samples=0.5, max_features=0.5).fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "0.924"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6. 随机森林\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train, target, random_state=0)\n",
    "clf = RandomForestClassifier(n_estimators=10,\n",
    "                             max_depth=None,\n",
    "                             min_samples_split=2,\n",
    "                             random_state=0).fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "0.922"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 7. 极端随机树模型\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train, target, random_state=0)\n",
    "clf = ExtraTreesClassifier(n_estimators=10,\n",
    "                             max_depth=None,\n",
    "                             min_samples_split=2,\n",
    "                             random_state=0).fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "text/plain": "0.934"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 8. AdaBoost模型\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train, target, random_state=0)\n",
    "clf = AdaBoostClassifier(n_estimators=100).fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "0.92"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 9. GBDT模型\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train, target, random_state=0)\n",
    "clf = GradientBoostingClassifier(n_estimators=100,\n",
    "                                 learning_rate=1.0,\n",
    "                                 max_depth=1,\n",
    "                                 random_state=0).fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sunjiabin/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/sunjiabin/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/sunjiabin/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/sunjiabin/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/sunjiabin/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/sunjiabin/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/sunjiabin/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/sunjiabin/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/sunjiabin/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/sunjiabin/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.90 (+/- 0.01) [LogisticRegression]\n",
      "accuracy: 0.93 (+/- 0.00) [RandomForestClassifier]\n",
      "accuracy: 0.47 (+/- 0.01) [GaussianNB]\n",
      "accuracy: 0.90 (+/- 0.00) [Voting]\n"
     ]
    }
   ],
   "source": [
    "# 10. 集成学习\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "stdscaler = StandardScaler()\n",
    "X = stdscaler.fit_transform(train)\n",
    "y = target\n",
    "clf1 = LogisticRegression(solver='lbfgs',\n",
    "                          multi_class='multinomial',\n",
    "                          random_state=1)\n",
    "clf2 = RandomForestClassifier(n_estimators=50, random_state=1)\n",
    "clf3 = GaussianNB()\n",
    "eclf = VotingClassifier(estimators=[('lr', clf1), ('rf', clf2), ('gnb', clf3)], voting='hard')\n",
    "\n",
    "for clf, label in zip([clf1, clf2, clf3, eclf],\n",
    "                      ['LogisticRegression', 'RandomForestClassifier', 'GaussianNB', 'Voting']):\n",
    "    scores = cross_val_score(clf, X, y, cv=5, scoring='accuracy')\n",
    "    print('accuracy: %0.2f (+/- %0.2f) [%s]' %(scores.mean(), scores.std(), label))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sunjiabin/anaconda3/envs/ml/lib/python3.7/site-packages/lightgbm/basic.py:1077: UserWarning: silent keyword has been found in `params` and will be ignored.\n",
      "Please use silent argument of the Dataset constructor to pass this parameter.\n",
      "  .format(key))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Unknown parameter: tree_method\n",
      "[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Unknown parameter: tree_method\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008817 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 30834\n",
      "[LightGBM] [Info] Number of data points in the train set: 1200, number of used features: 220\n",
      "[LightGBM] [Warning] Unknown parameter: colsample_bylevel\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Unknown parameter: tree_method\n",
      "[LightGBM] [Info] Start training from score -0.060989\n",
      "[LightGBM] [Info] Start training from score -2.827397\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1]\tvalid_0's multi_logloss: 0.316904\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[2]\tvalid_0's multi_logloss: 0.317248\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[3]\tvalid_0's multi_logloss: 0.317484\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[4]\tvalid_0's multi_logloss: 0.317591\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[5]\tvalid_0's multi_logloss: 0.317907\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[6]\tvalid_0's multi_logloss: 0.318182\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[7]\tvalid_0's multi_logloss: 0.31809\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[8]\tvalid_0's multi_logloss: 0.31851\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[9]\tvalid_0's multi_logloss: 0.319041\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[10]\tvalid_0's multi_logloss: 0.319477\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[11]\tvalid_0's multi_logloss: 0.320167\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[12]\tvalid_0's multi_logloss: 0.320905\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[13]\tvalid_0's multi_logloss: 0.320952\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[14]\tvalid_0's multi_logloss: 0.32143\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[15]\tvalid_0's multi_logloss: 0.322034\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[16]\tvalid_0's multi_logloss: 0.322216\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[17]\tvalid_0's multi_logloss: 0.322841\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[18]\tvalid_0's multi_logloss: 0.323525\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[19]\tvalid_0's multi_logloss: 0.324242\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[20]\tvalid_0's multi_logloss: 0.324574\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[21]\tvalid_0's multi_logloss: 0.324935\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[22]\tvalid_0's multi_logloss: 0.325027\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[23]\tvalid_0's multi_logloss: 0.32512\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[24]\tvalid_0's multi_logloss: 0.32555\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[25]\tvalid_0's multi_logloss: 0.325992\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[26]\tvalid_0's multi_logloss: 0.326173\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[27]\tvalid_0's multi_logloss: 0.326531\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[28]\tvalid_0's multi_logloss: 0.326676\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[29]\tvalid_0's multi_logloss: 0.326979\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[30]\tvalid_0's multi_logloss: 0.327593\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[31]\tvalid_0's multi_logloss: 0.327893\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[32]\tvalid_0's multi_logloss: 0.328132\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[33]\tvalid_0's multi_logloss: 0.328275\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[34]\tvalid_0's multi_logloss: 0.328528\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[35]\tvalid_0's multi_logloss: 0.328932\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[36]\tvalid_0's multi_logloss: 0.329398\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[37]\tvalid_0's multi_logloss: 0.329641\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[38]\tvalid_0's multi_logloss: 0.329665\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[39]\tvalid_0's multi_logloss: 0.330104\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[40]\tvalid_0's multi_logloss: 0.330517\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[41]\tvalid_0's multi_logloss: 0.330983\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[42]\tvalid_0's multi_logloss: 0.331135\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[43]\tvalid_0's multi_logloss: 0.33146\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[44]\tvalid_0's multi_logloss: 0.331789\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[45]\tvalid_0's multi_logloss: 0.332549\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[46]\tvalid_0's multi_logloss: 0.333105\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[47]\tvalid_0's multi_logloss: 0.333738\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[48]\tvalid_0's multi_logloss: 0.33413\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[49]\tvalid_0's multi_logloss: 0.334413\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[50]\tvalid_0's multi_logloss: 0.334729\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[51]\tvalid_0's multi_logloss: 0.335174\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[52]\tvalid_0's multi_logloss: 0.335512\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[53]\tvalid_0's multi_logloss: 0.335916\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[54]\tvalid_0's multi_logloss: 0.336197\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[55]\tvalid_0's multi_logloss: 0.336437\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[56]\tvalid_0's multi_logloss: 0.336644\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[57]\tvalid_0's multi_logloss: 0.33688\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[58]\tvalid_0's multi_logloss: 0.337236\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[59]\tvalid_0's multi_logloss: 0.337657\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[60]\tvalid_0's multi_logloss: 0.337981\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[61]\tvalid_0's multi_logloss: 0.338371\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[62]\tvalid_0's multi_logloss: 0.338747\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[63]\tvalid_0's multi_logloss: 0.339373\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[64]\tvalid_0's multi_logloss: 0.339827\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[65]\tvalid_0's multi_logloss: 0.3401\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[66]\tvalid_0's multi_logloss: 0.34047\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[67]\tvalid_0's multi_logloss: 0.340835\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[68]\tvalid_0's multi_logloss: 0.341167\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[69]\tvalid_0's multi_logloss: 0.341507\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[70]\tvalid_0's multi_logloss: 0.341657\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[71]\tvalid_0's multi_logloss: 0.342078\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[72]\tvalid_0's multi_logloss: 0.342655\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[73]\tvalid_0's multi_logloss: 0.34274\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[74]\tvalid_0's multi_logloss: 0.343254\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[75]\tvalid_0's multi_logloss: 0.343454\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[76]\tvalid_0's multi_logloss: 0.34394\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[77]\tvalid_0's multi_logloss: 0.344635\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[78]\tvalid_0's multi_logloss: 0.34502\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[79]\tvalid_0's multi_logloss: 0.345622\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[80]\tvalid_0's multi_logloss: 0.345855\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[81]\tvalid_0's multi_logloss: 0.346026\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[82]\tvalid_0's multi_logloss: 0.346322\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[83]\tvalid_0's multi_logloss: 0.347037\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[84]\tvalid_0's multi_logloss: 0.347257\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[85]\tvalid_0's multi_logloss: 0.347662\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[86]\tvalid_0's multi_logloss: 0.348004\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[87]\tvalid_0's multi_logloss: 0.348367\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[88]\tvalid_0's multi_logloss: 0.348658\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[89]\tvalid_0's multi_logloss: 0.349272\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[90]\tvalid_0's multi_logloss: 0.349774\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[91]\tvalid_0's multi_logloss: 0.350251\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[92]\tvalid_0's multi_logloss: 0.35066\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[93]\tvalid_0's multi_logloss: 0.350982\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[94]\tvalid_0's multi_logloss: 0.351274\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[95]\tvalid_0's multi_logloss: 0.351679\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[96]\tvalid_0's multi_logloss: 0.352063\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[97]\tvalid_0's multi_logloss: 0.352261\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[98]\tvalid_0's multi_logloss: 0.352606\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[99]\tvalid_0's multi_logloss: 0.353235\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[100]\tvalid_0's multi_logloss: 0.35365\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[101]\tvalid_0's multi_logloss: 0.353696\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's multi_logloss: 0.316904\n"
     ]
    }
   ],
   "source": [
    "# 11. LGB模型\n",
    "import lightgbm\n",
    "X_train, X_test, y_train, y_test = train_test_split(train, target, test_size=0.4, random_state=0)\n",
    "X_test, X_valid, y_test, y_valid = train_test_split(X_test, y_test, test_size=0.5, random_state=0)\n",
    "\n",
    "clf = lightgbm\n",
    "train_matrix = clf.Dataset(X_train, label=y_train)\n",
    "test_matrix = clf.Dataset(X_test, label=y_test)\n",
    "\n",
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'multiclass',\n",
    "    'metric': 'multi_logloss',\n",
    "    'min_child_weight': 1.5,\n",
    "    'num_leaves': 2**5,\n",
    "    'lambda_l2': 10,\n",
    "    'subsample': 0.7,\n",
    "    'colsample_bytree': 0.7,\n",
    "    'colsample_bylevel': 0.7,\n",
    "    'learning_rate': 0.03,\n",
    "    'tree_method': 'exact',\n",
    "    'seed': 2021,\n",
    "    'num_class': 2,\n",
    "    'silent': True\n",
    "}\n",
    "num_round = 10000\n",
    "early_stopping_rounds = 100\n",
    "model = clf.train(params,\n",
    "                  train_matrix,\n",
    "                  num_round,\n",
    "                  valid_sets=test_matrix,\n",
    "                  early_stopping_rounds=early_stopping_rounds)\n",
    "pre = model.predict(X_valid, num_iteration=model.best_iteration)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-mlogloss:0.67009\teval-mlogloss:0.67241\n",
      "[1]\ttrain-mlogloss:0.64850\teval-mlogloss:0.65310\n",
      "[2]\ttrain-mlogloss:0.62842\teval-mlogloss:0.63515\n",
      "[3]\ttrain-mlogloss:0.60912\teval-mlogloss:0.61784\n",
      "[4]\ttrain-mlogloss:0.59075\teval-mlogloss:0.60151\n",
      "[5]\ttrain-mlogloss:0.57336\teval-mlogloss:0.58619\n",
      "[6]\ttrain-mlogloss:0.55690\teval-mlogloss:0.57177\n",
      "[7]\ttrain-mlogloss:0.54149\teval-mlogloss:0.55826\n",
      "[8]\ttrain-mlogloss:0.52653\teval-mlogloss:0.54500\n",
      "[9]\ttrain-mlogloss:0.51234\teval-mlogloss:0.53292\n",
      "[10]\ttrain-mlogloss:0.49887\teval-mlogloss:0.52109\n",
      "[11]\ttrain-mlogloss:0.48619\teval-mlogloss:0.50997\n",
      "[12]\ttrain-mlogloss:0.47398\teval-mlogloss:0.49988\n",
      "[13]\ttrain-mlogloss:0.46261\teval-mlogloss:0.48999\n",
      "[14]\ttrain-mlogloss:0.45158\teval-mlogloss:0.48062\n",
      "[15]\ttrain-mlogloss:0.44105\teval-mlogloss:0.47175\n",
      "[16]\ttrain-mlogloss:0.43087\teval-mlogloss:0.46331\n",
      "[17]\ttrain-mlogloss:0.42110\teval-mlogloss:0.45521\n",
      "[18]\ttrain-mlogloss:0.41154\teval-mlogloss:0.44734\n",
      "[19]\ttrain-mlogloss:0.40249\teval-mlogloss:0.43999\n",
      "[20]\ttrain-mlogloss:0.39407\teval-mlogloss:0.43319\n",
      "[21]\ttrain-mlogloss:0.38588\teval-mlogloss:0.42655\n",
      "[22]\ttrain-mlogloss:0.37800\teval-mlogloss:0.42010\n",
      "[23]\ttrain-mlogloss:0.37052\teval-mlogloss:0.41413\n",
      "[24]\ttrain-mlogloss:0.36323\teval-mlogloss:0.40827\n",
      "[25]\ttrain-mlogloss:0.35628\teval-mlogloss:0.40304\n",
      "[26]\ttrain-mlogloss:0.34956\teval-mlogloss:0.39778\n",
      "[27]\ttrain-mlogloss:0.34308\teval-mlogloss:0.39271\n",
      "[28]\ttrain-mlogloss:0.33693\teval-mlogloss:0.38804\n",
      "[29]\ttrain-mlogloss:0.33110\teval-mlogloss:0.38384\n",
      "[30]\ttrain-mlogloss:0.32538\teval-mlogloss:0.37933\n",
      "[31]\ttrain-mlogloss:0.31995\teval-mlogloss:0.37526\n",
      "[32]\ttrain-mlogloss:0.31452\teval-mlogloss:0.37146\n",
      "[33]\ttrain-mlogloss:0.30935\teval-mlogloss:0.36779\n",
      "[34]\ttrain-mlogloss:0.30449\teval-mlogloss:0.36434\n",
      "[35]\ttrain-mlogloss:0.29974\teval-mlogloss:0.36131\n",
      "[36]\ttrain-mlogloss:0.29526\teval-mlogloss:0.35824\n",
      "[37]\ttrain-mlogloss:0.29090\teval-mlogloss:0.35520\n",
      "[38]\ttrain-mlogloss:0.28667\teval-mlogloss:0.35227\n",
      "[39]\ttrain-mlogloss:0.28255\teval-mlogloss:0.34978\n",
      "[40]\ttrain-mlogloss:0.27862\teval-mlogloss:0.34716\n",
      "[41]\ttrain-mlogloss:0.27487\teval-mlogloss:0.34475\n",
      "[42]\ttrain-mlogloss:0.27115\teval-mlogloss:0.34260\n",
      "[43]\ttrain-mlogloss:0.26762\teval-mlogloss:0.34040\n",
      "[44]\ttrain-mlogloss:0.26420\teval-mlogloss:0.33816\n",
      "[45]\ttrain-mlogloss:0.26083\teval-mlogloss:0.33634\n",
      "[46]\ttrain-mlogloss:0.25782\teval-mlogloss:0.33464\n",
      "[47]\ttrain-mlogloss:0.25469\teval-mlogloss:0.33276\n",
      "[48]\ttrain-mlogloss:0.25181\teval-mlogloss:0.33118\n",
      "[49]\ttrain-mlogloss:0.24889\teval-mlogloss:0.32968\n",
      "[50]\ttrain-mlogloss:0.24608\teval-mlogloss:0.32841\n",
      "[51]\ttrain-mlogloss:0.24338\teval-mlogloss:0.32704\n",
      "[52]\ttrain-mlogloss:0.24064\teval-mlogloss:0.32557\n",
      "[53]\ttrain-mlogloss:0.23800\teval-mlogloss:0.32437\n",
      "[54]\ttrain-mlogloss:0.23564\teval-mlogloss:0.32311\n",
      "[55]\ttrain-mlogloss:0.23324\teval-mlogloss:0.32212\n",
      "[56]\ttrain-mlogloss:0.23088\teval-mlogloss:0.32121\n",
      "[57]\ttrain-mlogloss:0.22848\teval-mlogloss:0.32018\n",
      "[58]\ttrain-mlogloss:0.22622\teval-mlogloss:0.31923\n",
      "[59]\ttrain-mlogloss:0.22412\teval-mlogloss:0.31833\n",
      "[60]\ttrain-mlogloss:0.22206\teval-mlogloss:0.31748\n",
      "[61]\ttrain-mlogloss:0.21990\teval-mlogloss:0.31693\n",
      "[62]\ttrain-mlogloss:0.21801\teval-mlogloss:0.31633\n",
      "[63]\ttrain-mlogloss:0.21605\teval-mlogloss:0.31573\n",
      "[64]\ttrain-mlogloss:0.21410\teval-mlogloss:0.31522\n",
      "[65]\ttrain-mlogloss:0.21236\teval-mlogloss:0.31462\n",
      "[66]\ttrain-mlogloss:0.21072\teval-mlogloss:0.31430\n",
      "[67]\ttrain-mlogloss:0.20909\teval-mlogloss:0.31391\n",
      "[68]\ttrain-mlogloss:0.20721\teval-mlogloss:0.31356\n",
      "[69]\ttrain-mlogloss:0.20584\teval-mlogloss:0.31329\n",
      "[70]\ttrain-mlogloss:0.20414\teval-mlogloss:0.31317\n",
      "[71]\ttrain-mlogloss:0.20263\teval-mlogloss:0.31301\n",
      "[72]\ttrain-mlogloss:0.20105\teval-mlogloss:0.31299\n",
      "[73]\ttrain-mlogloss:0.19958\teval-mlogloss:0.31291\n",
      "[74]\ttrain-mlogloss:0.19810\teval-mlogloss:0.31286\n",
      "[75]\ttrain-mlogloss:0.19655\teval-mlogloss:0.31247\n",
      "[76]\ttrain-mlogloss:0.19503\teval-mlogloss:0.31237\n",
      "[77]\ttrain-mlogloss:0.19357\teval-mlogloss:0.31215\n",
      "[78]\ttrain-mlogloss:0.19211\teval-mlogloss:0.31206\n",
      "[79]\ttrain-mlogloss:0.19068\teval-mlogloss:0.31211\n",
      "[80]\ttrain-mlogloss:0.18926\teval-mlogloss:0.31197\n",
      "[81]\ttrain-mlogloss:0.18787\teval-mlogloss:0.31216\n",
      "[82]\ttrain-mlogloss:0.18665\teval-mlogloss:0.31233\n",
      "[83]\ttrain-mlogloss:0.18546\teval-mlogloss:0.31220\n",
      "[84]\ttrain-mlogloss:0.18411\teval-mlogloss:0.31196\n",
      "[85]\ttrain-mlogloss:0.18281\teval-mlogloss:0.31220\n",
      "[86]\ttrain-mlogloss:0.18159\teval-mlogloss:0.31242\n",
      "[87]\ttrain-mlogloss:0.18016\teval-mlogloss:0.31241\n",
      "[88]\ttrain-mlogloss:0.17916\teval-mlogloss:0.31268\n",
      "[89]\ttrain-mlogloss:0.17802\teval-mlogloss:0.31273\n",
      "[90]\ttrain-mlogloss:0.17687\teval-mlogloss:0.31302\n",
      "[91]\ttrain-mlogloss:0.17578\teval-mlogloss:0.31306\n",
      "[92]\ttrain-mlogloss:0.17482\teval-mlogloss:0.31307\n",
      "[93]\ttrain-mlogloss:0.17368\teval-mlogloss:0.31318\n",
      "[94]\ttrain-mlogloss:0.17266\teval-mlogloss:0.31340\n",
      "[95]\ttrain-mlogloss:0.17156\teval-mlogloss:0.31374\n",
      "[96]\ttrain-mlogloss:0.17056\teval-mlogloss:0.31383\n",
      "[97]\ttrain-mlogloss:0.16945\teval-mlogloss:0.31405\n",
      "[98]\ttrain-mlogloss:0.16827\teval-mlogloss:0.31443\n",
      "[99]\ttrain-mlogloss:0.16732\teval-mlogloss:0.31448\n",
      "[100]\ttrain-mlogloss:0.16624\teval-mlogloss:0.31466\n",
      "[101]\ttrain-mlogloss:0.16525\teval-mlogloss:0.31514\n",
      "[102]\ttrain-mlogloss:0.16437\teval-mlogloss:0.31523\n",
      "[103]\ttrain-mlogloss:0.16328\teval-mlogloss:0.31534\n",
      "[104]\ttrain-mlogloss:0.16245\teval-mlogloss:0.31590\n",
      "[105]\ttrain-mlogloss:0.16150\teval-mlogloss:0.31633\n",
      "[106]\ttrain-mlogloss:0.16046\teval-mlogloss:0.31636\n",
      "[107]\ttrain-mlogloss:0.15951\teval-mlogloss:0.31663\n",
      "[108]\ttrain-mlogloss:0.15870\teval-mlogloss:0.31681\n",
      "[109]\ttrain-mlogloss:0.15792\teval-mlogloss:0.31710\n",
      "[110]\ttrain-mlogloss:0.15723\teval-mlogloss:0.31740\n",
      "[111]\ttrain-mlogloss:0.15637\teval-mlogloss:0.31744\n",
      "[112]\ttrain-mlogloss:0.15564\teval-mlogloss:0.31793\n",
      "[113]\ttrain-mlogloss:0.15478\teval-mlogloss:0.31849\n",
      "[114]\ttrain-mlogloss:0.15383\teval-mlogloss:0.31870\n",
      "[115]\ttrain-mlogloss:0.15302\teval-mlogloss:0.31887\n",
      "[116]\ttrain-mlogloss:0.15206\teval-mlogloss:0.31926\n",
      "[117]\ttrain-mlogloss:0.15118\teval-mlogloss:0.31946\n",
      "[118]\ttrain-mlogloss:0.15037\teval-mlogloss:0.31978\n",
      "[119]\ttrain-mlogloss:0.14963\teval-mlogloss:0.32014\n",
      "[120]\ttrain-mlogloss:0.14873\teval-mlogloss:0.32030\n",
      "[121]\ttrain-mlogloss:0.14787\teval-mlogloss:0.32091\n",
      "[122]\ttrain-mlogloss:0.14701\teval-mlogloss:0.32118\n",
      "[123]\ttrain-mlogloss:0.14646\teval-mlogloss:0.32156\n",
      "[124]\ttrain-mlogloss:0.14568\teval-mlogloss:0.32195\n",
      "[125]\ttrain-mlogloss:0.14492\teval-mlogloss:0.32234\n",
      "[126]\ttrain-mlogloss:0.14412\teval-mlogloss:0.32286\n",
      "[127]\ttrain-mlogloss:0.14340\teval-mlogloss:0.32358\n",
      "[128]\ttrain-mlogloss:0.14255\teval-mlogloss:0.32375\n",
      "[129]\ttrain-mlogloss:0.14190\teval-mlogloss:0.32371\n",
      "[130]\ttrain-mlogloss:0.14110\teval-mlogloss:0.32389\n",
      "[131]\ttrain-mlogloss:0.14046\teval-mlogloss:0.32412\n",
      "[132]\ttrain-mlogloss:0.13981\teval-mlogloss:0.32463\n",
      "[133]\ttrain-mlogloss:0.13920\teval-mlogloss:0.32503\n",
      "[134]\ttrain-mlogloss:0.13858\teval-mlogloss:0.32537\n",
      "[135]\ttrain-mlogloss:0.13796\teval-mlogloss:0.32570\n",
      "[136]\ttrain-mlogloss:0.13728\teval-mlogloss:0.32629\n",
      "[137]\ttrain-mlogloss:0.13651\teval-mlogloss:0.32643\n",
      "[138]\ttrain-mlogloss:0.13570\teval-mlogloss:0.32675\n",
      "[139]\ttrain-mlogloss:0.13502\teval-mlogloss:0.32724\n",
      "[140]\ttrain-mlogloss:0.13432\teval-mlogloss:0.32744\n",
      "[141]\ttrain-mlogloss:0.13387\teval-mlogloss:0.32773\n",
      "[142]\ttrain-mlogloss:0.13333\teval-mlogloss:0.32800\n",
      "[143]\ttrain-mlogloss:0.13261\teval-mlogloss:0.32857\n",
      "[144]\ttrain-mlogloss:0.13193\teval-mlogloss:0.32877\n",
      "[145]\ttrain-mlogloss:0.13131\teval-mlogloss:0.32910\n",
      "[146]\ttrain-mlogloss:0.13071\teval-mlogloss:0.32970\n",
      "[147]\ttrain-mlogloss:0.13006\teval-mlogloss:0.33014\n",
      "[148]\ttrain-mlogloss:0.12953\teval-mlogloss:0.33034\n",
      "[149]\ttrain-mlogloss:0.12892\teval-mlogloss:0.33054\n",
      "[150]\ttrain-mlogloss:0.12817\teval-mlogloss:0.33082\n",
      "[151]\ttrain-mlogloss:0.12771\teval-mlogloss:0.33114\n",
      "[152]\ttrain-mlogloss:0.12730\teval-mlogloss:0.33135\n",
      "[153]\ttrain-mlogloss:0.12674\teval-mlogloss:0.33169\n",
      "[154]\ttrain-mlogloss:0.12611\teval-mlogloss:0.33216\n",
      "[155]\ttrain-mlogloss:0.12543\teval-mlogloss:0.33237\n",
      "[156]\ttrain-mlogloss:0.12498\teval-mlogloss:0.33277\n",
      "[157]\ttrain-mlogloss:0.12435\teval-mlogloss:0.33314\n",
      "[158]\ttrain-mlogloss:0.12375\teval-mlogloss:0.33334\n",
      "[159]\ttrain-mlogloss:0.12333\teval-mlogloss:0.33343\n",
      "[160]\ttrain-mlogloss:0.12277\teval-mlogloss:0.33350\n",
      "[161]\ttrain-mlogloss:0.12209\teval-mlogloss:0.33394\n",
      "[162]\ttrain-mlogloss:0.12151\teval-mlogloss:0.33424\n",
      "[163]\ttrain-mlogloss:0.12099\teval-mlogloss:0.33454\n",
      "[164]\ttrain-mlogloss:0.12051\teval-mlogloss:0.33483\n",
      "[165]\ttrain-mlogloss:0.12016\teval-mlogloss:0.33510\n",
      "[166]\ttrain-mlogloss:0.11970\teval-mlogloss:0.33548\n",
      "[167]\ttrain-mlogloss:0.11936\teval-mlogloss:0.33554\n",
      "[168]\ttrain-mlogloss:0.11904\teval-mlogloss:0.33569\n",
      "[169]\ttrain-mlogloss:0.11848\teval-mlogloss:0.33613\n",
      "[170]\ttrain-mlogloss:0.11802\teval-mlogloss:0.33613\n",
      "[171]\ttrain-mlogloss:0.11747\teval-mlogloss:0.33639\n",
      "[172]\ttrain-mlogloss:0.11700\teval-mlogloss:0.33659\n",
      "[173]\ttrain-mlogloss:0.11645\teval-mlogloss:0.33696\n",
      "[174]\ttrain-mlogloss:0.11607\teval-mlogloss:0.33751\n",
      "[175]\ttrain-mlogloss:0.11562\teval-mlogloss:0.33795\n",
      "[176]\ttrain-mlogloss:0.11522\teval-mlogloss:0.33797\n",
      "[177]\ttrain-mlogloss:0.11480\teval-mlogloss:0.33800\n",
      "[178]\ttrain-mlogloss:0.11440\teval-mlogloss:0.33817\n",
      "[179]\ttrain-mlogloss:0.11400\teval-mlogloss:0.33840\n",
      "[180]\ttrain-mlogloss:0.11358\teval-mlogloss:0.33849\n",
      "[181]\ttrain-mlogloss:0.11307\teval-mlogloss:0.33914\n",
      "[182]\ttrain-mlogloss:0.11265\teval-mlogloss:0.33917\n",
      "[183]\ttrain-mlogloss:0.11222\teval-mlogloss:0.33907\n",
      "[184]\ttrain-mlogloss:0.11193\teval-mlogloss:0.33921\n"
     ]
    }
   ],
   "source": [
    "# 12. XGB 模型\n",
    "# 11. LGB模型\n",
    "import xgboost\n",
    "X_train, X_test, y_train, y_test = train_test_split(train, target, test_size=0.4, random_state=0)\n",
    "X_test, X_valid, y_test, y_valid = train_test_split(X_test, y_test, test_size=0.5, random_state=0)\n",
    "\n",
    "clf = xgboost\n",
    "train_matrix = clf.DMatrix(X_train, label=y_train, missing=-1)\n",
    "test_matrix = clf.DMatrix(X_test, label=y_test, missing=-1)\n",
    "z = clf.DMatrix(X_valid, label=y_valid, missing=-1)\n",
    "params = {\n",
    "    'booster': 'gbtree',\n",
    "    'objective': 'multi:softprob',\n",
    "    'eval_metric': 'mlogloss',\n",
    "    'gamma': 1,\n",
    "    'min_child_weight': 1.5,\n",
    "    'max_depth': 5,\n",
    "    'lambda': 10,\n",
    "    'subsample': 0.7,\n",
    "    'colsample_bytree': 0.7,\n",
    "    'colsample_bylevel': 0.7,\n",
    "    'eta': 0.03,\n",
    "    'tree_method': 'exact',\n",
    "    'seed': 2021,\n",
    "    'num_class': 2\n",
    "}\n",
    "\n",
    "num_round = 10000\n",
    "early_stopping_rounds = 100\n",
    "watchlist = [(train_matrix, 'train'), (test_matrix, 'eval')]\n",
    "\n",
    "model = clf.train(params,\n",
    "                  train_matrix,\n",
    "                  num_round,\n",
    "                  evals=watchlist,\n",
    "                  early_stopping_rounds=early_stopping_rounds)\n",
    "pre = model.predict(z, ntree_limit=model.best_ntree_limit)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score:  0.9475\n"
     ]
    }
   ],
   "source": [
    "print('score: ', np.mean((pre[:,1] > 0.5) == y_valid))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 自己封装模型"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Stacking Bootstrap Bagging"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}